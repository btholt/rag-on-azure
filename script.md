# Naive

Let's write main.js

```javascript
// you need this one every time
import callAzureAI from "./callAzureAI.js";

import getRagResults from "./naive.js";
const content = "death cab";

const ragResults = await getRagResults(content);
console.log(ragResults);
const result = await callAzureAI(content, ragResults);
console.log(result);
```

- Let's go sign up for Neon - show them around
- Let's go sign up for Azure AI Foundry
  - DeepSeek R1
  - text-embeddings
- Get the .env for Neon and for the DeepSeek R1 model

callAzureAI.js

```javascript
const endpoint = process.env.AZURE_AI_ENDPOINT;
const apiKey = process.env.AZURE_AI_API_KEY;
const deploymentName = process.env.AZURE_AI_DEPLOYMENT_NAME;

// Use String.fromCharCode(27) to create the actual escape character
const ESC = String.fromCharCode(27);
let systemPrompt = `You are a helpful music recommendation assistant. Use the provided music review information to answer questions about music, artists, and albums. You must give at least five recommendations. Use ANSI terminal coloring for emphasis - here are examples:
- Blue text: ${ESC}[34mBlue Text${ESC}[0m
- Bold red text: ${ESC}[1;31mBold Red Text${ESC}[0m
- Artist names should be ${ESC}[1;36mcyan and bold${ESC}[0m 
- Album names should be ${ESC}[1;33myellow and bold${ESC}[0m
- Scores should be ${ESC}[1;31mbold and red${ESC}[0m
- Make use of emojis to make your responses more engaging and fun! üéµüé∂
`;

async function callAzureAI(userQuery) {
  try {
    console.log("calling Azure AI service, please wait a while...");

    // // Format RAG results into a readable context
    // let formattedResults = "";
    let formattedSystemPrompt = systemPrompt;
    // if (ragResults && ragResults.length > 0) {
    //   formattedSystemPrompt += `\n- You will be provided a list of music reviews from Pitchfork to help you answer questions.`;
    //   formattedResults =
    //     "Based on your query, here are some relevant music reviews:\n\n";
    //   ragResults.forEach((result, index) => {
    //     formattedResults += `${index + 1}. Artist: ${result.artist}, Album: ${
    //       result.title
    //     }, Score: ${result.score}/10\n`;
    //   });
    }

    const messages = [
      {
        role: "system",
        content: formattedSystemPrompt,
      },
      {
        role: "user",
        content: `${formattedResults}\n\nMy question is: ${userQuery}`,
      },
    ];

    console.log(
      "Sending the following messages to AI:",
      JSON.stringify(messages, null, 2)
    );

    const response = await fetch(endpoint, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "api-key": apiKey,
      },
      body: JSON.stringify({
        messages: messages,
        model: deploymentName,
      }),
    });

    if (!response.ok) {
      throw new Error(
        `API request failed with status ${
          response.status
        }: ${await response.text()}`
      );
    }

    const result = await response.json();
    console.log("Response from AI service received");

    if (result.choices && result.choices.length > 0) {
      return result.choices[0].message.content;
    }
    return "No response generated by the AI service.";
  } catch (error) {
    console.error(`An error occurred: ${error.message}`);
    return `Error: ${error.message}`;
  }
}

export default callAzureAI;
```

- Run this without any RAG. Okay now try

naive.js

```javascript

```

Add to main.js

```javascript
const ragResults = await getRagResults(content);
console.log(ragResults);
const result = await callAzureAI(content, ragResults);
```

Add to callAzureAI.js

```javascript
// // Format RAG results into a readable context
let formattedResults = "";
let formattedSystemPrompt = systemPrompt;
if (ragResults && ragResults.length > 0) {
  formattedSystemPrompt += `\n- You will be provided a list of music reviews from Pitchfork to help you answer questions.`;
  formattedResults =
    "Based on your query, here are some relevant music reviews:\n\n";
  ragResults.forEach((result, index) => {
    formattedResults += `${index + 1}. Artist: ${result.artist}, Album: ${
      result.title
    }, Score: ${result.score}/10\n`;
  });
}
```

# Vector Search

- C/P createEmbeddings.js, 
- show one quick one running, 
- show it in Neon,
  - Make a fork
  - Do a PITR 
- show tokens being used

Now write vectorSearch.js

```javascript
import { neon } from "@neondatabase/serverless";

const endpoint = process.env.AZURE_AI_EMBEDDING_ENDPOINT;
const apiKey = process.env.AZURE_AI_EMBEDDING_API_KEY;
const embeddingsDeploymentName = process.env.AZURE_AI_EMBEDDING_DEPLOYMENT_NAME;

async function generateEmbedding(query) {
  try {
    const response = await fetch(endpoint, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "api-key": apiKey,
        "x-ms-model-mesh-model-name": embeddingsDeploymentName,
      },
      body: JSON.stringify({
        input: query,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(
        `API request failed with status ${response.status}: ${errorText}`
      );
    }

    const result = await response.json();
    return result.data[0].embedding;
  } catch (error) {
    console.error(`Error generating embedding: ${error.message}`);
    throw error;
  }
}

async function findSimilarBandsVector(query, limit = 50) {
  try {
    const sql = neon(process.env.DATABASE_WITH_EMBEDDINGS_URL);

    // Generate embedding for the query
    const queryEmbedding = await generateEmbedding(query);

    const vectorString = `[${queryEmbedding.join(",")}]`;

    // Search for similar reviews using cosine similarity
    const results = await sql`
      SELECT 
        reviewid, 
        title, 
        artist, 
        score, 
        1 - (embedding <=> ${vectorString}) as similarity
      FROM 
        embeddings
      ORDER BY 
        similarity DESC
      LIMIT ${limit}
    `;

    return results;
  } catch (error) {
    console.error("Error in vector search:", error);
    throw error;
  }
}

export default findSimilarBandsVector;
```

Now change main.js

```javascript
import getRagResults from "./vectorSearch.js";
```

# LLM Cleanup

Create llmCleanup.js
```javascript
import vectorSearch from "./vectorSearch.js";

const endpoint = process.env.AZURE_AI_ENDPOINT;
const apiKey = process.env.AZURE_AI_API_KEY;
const deploymentName = process.env.AZURE_AI_DEPLOYMENT_NAME;

async function cleanupQueryWithAzureAI(query) {
  if (!endpoint || !apiKey || !deploymentName) {
    console.warn("‚ö†Ô∏è Azure AI credentials not found, using original query");
    return query;
  }

  try {
    const response = await fetch(endpoint, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "api-key": apiKey,
        "x-ms-model-mesh-model-name": deploymentName,
      },
      body: JSON.stringify({
        messages: [
          {
            role: "system",
            content:
              "You are a query optimizer for RAG systems. Your goal is to reformulate user queries to be more effective for retrieval from a vector database. Make the query clear, specific, and focused on key information needs without changing the original intent. The vector database is a list of music reviews with embeddings generated from the text. Please wrap your final response in <query> tags. This is keyword based that is going to be querying against titles, genres, artist names, and written reviews so be sure to include the most important keywords in your query and no superfluous terms.",
          },
          {
            role: "user",
            content: `Please optimize this query for vector search: "${query}"`,
          },
        ],
        temperature: 0.3,
      }),
    });

    const responseData = await response.json();
    console.log("üîç Azure AI response:", responseData.choices);
    const totalResponse = responseData.choices[0].message.content.trim();
    const cleanedQuery = totalResponse
      .split("<query>")
      .pop()
      .split("</query>")[0];
    console.log(`üîç Original query: "${query}"`);
    console.log(`‚ú® Optimized query: "${cleanedQuery}"`);

    return cleanedQuery;
  } catch (error) {
    console.error("‚ùå Error cleaning up query with Azure AI:", error);
    console.log("‚ö†Ô∏è Falling back to original query");
    return query;
  }
}

export default async function rag(query) {
  const cleanedQuery = await cleanupQueryWithAzureAI(query);
  const similarBands = await vectorSearch(cleanedQuery);
  return similarBands;
}
```

In main.js

```javascript
import getRagResults from "./llmCleanup.js";
```